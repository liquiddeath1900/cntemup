{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¥ CNTEM'UP â€” Train Custom Bottle/Can Detector\n",
        "\n",
        "This notebook trains a **YOLOv8n** model to detect bottles and cans,\n",
        "then exports it to **ONNX** for browser use.\n",
        "\n",
        "**Before running:**\n",
        "1. Go to Runtime â†’ Change runtime type â†’ **T4 GPU**\n",
        "2. Get your Roboflow API key from: app.roboflow.com â†’ Settings â†’ API Key\n",
        "3. Run each cell in order\n",
        "\n",
        "**Time:** ~1 hour total on free Colab T4"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Dependencies"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics roboflow onnx onnxsim -q\n",
        "print('âœ… Dependencies installed!')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify GPU is available\n",
        "import torch\n",
        "print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"âŒ NO GPU â€” go to Runtime â†’ Change runtime type â†’ T4 GPU\"}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Download Dataset from Roboflow\n",
        "\n",
        "**Option A:** Use the public \"Bottle and Can\" dataset (1,200 images, 2 classes)\n",
        "\n",
        "**Option B:** Use your own Roboflow project (if you uploaded + labeled your own images)\n",
        "\n",
        "Fill in your API key below and choose your option."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# âš ï¸ FILL THESE IN:\n",
        "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "\n",
        "ROBOFLOW_API_KEY = \"YOUR_API_KEY_HERE\"  # Get from app.roboflow.com â†’ Settings\n",
        "\n",
        "# Option A: Public \"Bottle and Can\" dataset (recommended to start)\n",
        "WORKSPACE = \"bouteille\"\n",
        "PROJECT = \"bottle-and-can\"\n",
        "VERSION = 1\n",
        "\n",
        "# Option B: Your own project â€” uncomment and fill in:\n",
        "# WORKSPACE = \"your-workspace-name\"\n",
        "# PROJECT = \"your-project-name\"\n",
        "# VERSION = 1\n",
        "\n",
        "#â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(WORKSPACE).project(PROJECT)\n",
        "version = project.version(VERSION)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "dataset_path = dataset.location\n",
        "print(f'\\nâœ… Dataset downloaded to: {dataset_path}')\n",
        "\n",
        "# Show what we got\n",
        "import os\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    img_dir = os.path.join(dataset_path, split, 'images')\n",
        "    if os.path.exists(img_dir):\n",
        "        count = len(os.listdir(img_dir))\n",
        "        print(f'  {split}: {count} images')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Check Class Balance\n",
        "\n",
        "Make sure bottle and can have roughly equal representation.\n",
        "If one class has 5x more than the other, accuracy will suffer."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "class_counts = Counter()\n",
        "lbl_dir = os.path.join(dataset_path, 'train', 'labels')\n",
        "\n",
        "for fname in os.listdir(lbl_dir):\n",
        "    if fname.endswith('.txt'):\n",
        "        with open(os.path.join(lbl_dir, fname)) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    class_counts[int(parts[0])] += 1\n",
        "\n",
        "# Read class names from data.yaml\n",
        "import yaml\n",
        "with open(os.path.join(dataset_path, 'data.yaml')) as f:\n",
        "    data_yaml = yaml.safe_load(f)\n",
        "\n",
        "names = data_yaml.get('names', {})\n",
        "if isinstance(names, list):\n",
        "    names = {i: n for i, n in enumerate(names)}\n",
        "\n",
        "print('ðŸ“Š Class distribution (training set):')\n",
        "for cls_id, count in sorted(class_counts.items()):\n",
        "    name = names.get(cls_id, f'class_{cls_id}')\n",
        "    print(f'  {name} (id={cls_id}): {count} annotations')\n",
        "\n",
        "total = sum(class_counts.values())\n",
        "print(f'\\n  Total: {total} annotations')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Visualize Some Training Images\n",
        "\n",
        "Sanity check â€” make sure the labels look right."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "colors = ['#10b981', '#ef4444', '#3b82f6', '#f59e0b']\n",
        "\n",
        "img_dir = os.path.join(dataset_path, 'train', 'images')\n",
        "lbl_dir = os.path.join(dataset_path, 'train', 'labels')\n",
        "img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "samples = random.sample(img_files, min(6, len(img_files)))\n",
        "\n",
        "for ax, fname in zip(axes.flat, samples):\n",
        "    img = Image.open(os.path.join(img_dir, fname))\n",
        "    w, h = img.size\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(fname[:20], fontsize=8)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Draw labels\n",
        "    lbl_file = os.path.splitext(fname)[0] + '.txt'\n",
        "    lbl_path = os.path.join(lbl_dir, lbl_file)\n",
        "    if os.path.exists(lbl_path):\n",
        "        with open(lbl_path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    cls_id = int(parts[0])\n",
        "                    cx, cy, bw, bh = map(float, parts[1:5])\n",
        "                    x1 = (cx - bw/2) * w\n",
        "                    y1 = (cy - bh/2) * h\n",
        "                    box_w = bw * w\n",
        "                    box_h = bh * h\n",
        "                    color = colors[cls_id % len(colors)]\n",
        "                    rect = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
        "                    ax.add_patch(rect)\n",
        "                    label = names.get(cls_id, f'cls_{cls_id}')\n",
        "                    ax.text(x1, y1-5, label, color=color, fontsize=8, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Training Samples with Labels', fontsize=14, y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: TRAIN ðŸš€\n",
        "\n",
        "This is where the magic happens. Takes ~30-90 min on a T4 GPU.\n",
        "\n",
        "**Key settings:**\n",
        "- `epochs=100` â€” model will early-stop if it plateaus\n",
        "- `imgsz=640` â€” standard YOLO input (matches our React hook)\n",
        "- `batch=16` â€” sweet spot for free Colab T4 (16GB VRAM)\n",
        "- Starting from pre-trained COCO weights (transfer learning = way faster + better)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Start from COCO pre-trained weights (transfer learning)\n",
        "model = YOLO('yolov8n.pt')  # nano = smallest, fastest\n",
        "\n",
        "# Train!\n",
        "results = model.train(\n",
        "    data=os.path.join(dataset_path, 'data.yaml'),\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=20,        # Early stop if no improvement for 20 epochs\n",
        "    device=0,           # GPU\n",
        "    workers=2,          # Colab has limited CPU\n",
        "    project='cntemup',  # Output folder\n",
        "    name='bottle_can',  # Run name\n",
        "    \n",
        "    # Augmentation\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=10,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.1,\n",
        ")\n",
        "\n",
        "print('\\nâœ… Training complete!')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Check Results\n",
        "\n",
        "**What to look for:**\n",
        "- `mAP50 > 0.80` = good\n",
        "- `mAP50 > 0.90` = excellent\n",
        "- `mAP50 < 0.60` = needs more/better training data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Training curves\n",
        "print('ðŸ“ˆ Training Results:')\n",
        "display(Image(filename='cntemup/bottle_can/results.png', width=900))\n",
        "\n",
        "# Confusion matrix\n",
        "print('\\nðŸ”„ Confusion Matrix:')\n",
        "display(Image(filename='cntemup/bottle_can/confusion_matrix.png', width=600))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation predictions â€” see how the model performs\n",
        "print('ðŸŽ¯ Validation Predictions:')\n",
        "try:\n",
        "    display(Image(filename='cntemup/bottle_can/val_batch0_pred.jpg', width=900))\n",
        "except:\n",
        "    print('(validation images not generated â€” this is fine)')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Test on Sample Images\n",
        "\n",
        "Run the model on validation images to see it in action."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model from training\n",
        "best_model = YOLO('cntemup/bottle_can/weights/best.pt')\n",
        "\n",
        "# Run on validation images\n",
        "val_imgs = os.path.join(dataset_path, 'valid', 'images')\n",
        "test_results = best_model.predict(\n",
        "    source=val_imgs,\n",
        "    save=True,\n",
        "    conf=0.35,\n",
        "    project='cntemup',\n",
        "    name='test_predictions',\n",
        ")\n",
        "\n",
        "# Show some results\n",
        "pred_dir = 'cntemup/test_predictions'\n",
        "pred_files = [f for f in os.listdir(pred_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "for ax, fname in zip(axes.flat, pred_files[:6]):\n",
        "    img = Image.open(os.path.join(pred_dir, fname))\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Model Predictions', fontsize=14, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Print metrics\n",
        "metrics = best_model.val(data=os.path.join(dataset_path, 'data.yaml'))\n",
        "print(f'\\nðŸ“Š Final Metrics:')\n",
        "print(f'  mAP50:    {metrics.box.map50:.3f}')\n",
        "print(f'  mAP50-95: {metrics.box.map:.3f}')\n",
        "print(f'  Precision: {metrics.box.mp:.3f}')\n",
        "print(f'  Recall:    {metrics.box.mr:.3f}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Export to ONNX\n",
        "\n",
        "This converts the model to a format that runs in the browser via ONNX Runtime Web."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to ONNX for browser\n",
        "best_model = YOLO('cntemup/bottle_can/weights/best.pt')\n",
        "\n",
        "onnx_path = best_model.export(\n",
        "    format='onnx',\n",
        "    opset=12,        # Browser-compatible\n",
        "    simplify=True,   # Smaller file, faster inference\n",
        "    imgsz=640,       # Must match INPUT_SIZE in React hook\n",
        ")\n",
        "\n",
        "import os\n",
        "size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "print(f'\\nâœ… Exported to: {onnx_path}')\n",
        "print(f'ðŸ“¦ Model size: {size_mb:.1f} MB')\n",
        "print(f'\\nNext: Download this file and put it at:')\n",
        "print(f'  app/public/models/bottle-can.onnx')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Download the Model\n",
        "\n",
        "Click the download button or run this cell.\n",
        "\n",
        "Then put the file at: **`app/public/models/bottle-can.onnx`** in your CNTEM'UP project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the ONNX model\n",
        "files.download('cntemup/bottle_can/weights/best.onnx')\n",
        "\n",
        "print('\\nðŸŽ‰ Done! Put this file at:')\n",
        "print('   app/public/models/bottle-can.onnx')\n",
        "print('\\nThe app will auto-detect it and switch from COCO-SSD to your custom model.')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŽ‰ You're done!\n",
        "\n",
        "**What just happened:**\n",
        "1. Downloaded a labeled bottle/can dataset\n",
        "2. Trained YOLOv8n on it (transfer learning from COCO)\n",
        "3. Exported to ONNX for browser use\n",
        "\n",
        "**Next steps:**\n",
        "1. Put `best.onnx` â†’ `app/public/models/bottle-can.onnx`\n",
        "2. Run `npm run dev` â€” the app auto-detects the model\n",
        "3. Footer will show \"YOLOv8 Custom engine\"\n",
        "4. Test and tune `CONF_THRESHOLD` in `useYoloDetection.js`\n",
        "\n",
        "**Want better accuracy?**\n",
        "- Add your own photos to the Roboflow project\n",
        "- Re-generate the dataset version\n",
        "- Re-run this notebook\n",
        "- Each iteration gets better!"
      ],
      "metadata": {}
    }
  ]
}
